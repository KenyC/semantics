{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial\n",
    "\n",
    "This repository provides an implementation of basic compositional semantics ; it can be used to check truth-value of sentences against models, type correctness, first-order formulas for truth conditions. The following provides an introduction.\n",
    "\n",
    "## Basic functionality\n",
    "\n",
    "Let's consider the following model:\n",
    "\n",
    "  * Ahmed and Ben are the men\n",
    "  * Rosa and Ren are the women\n",
    "  * All but Ren smiles\n",
    "  * Ahmed loves Rosa, who loves Ren, who loves Ahmed\n",
    "\n",
    "Against this model, we want to find the truth-value of the following sentences:\n",
    "\n",
    "  1. Ahmed smiles.\n",
    "  1. Rosa loves Ahmed.\n",
    "  1. Every man smiles.\n",
    "\n",
    "This is done as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 1 is True\n",
      "Sentence 2 is False\n",
      "Sentence 3 is True\n"
     ]
    }
   ],
   "source": [
    "# Let's first import our model (implemented by default in nonlogical.py ; see later to construct one's own models):\n",
    "# This file also contains the non-logical vocab associated with the model\n",
    "from nonlogical import *\n",
    "\n",
    "# \"every\" is part of the logical vocab and needs its own import\n",
    "from logical import every\n",
    "\n",
    "# Finally let's set up the system to use the rules of composition in H&K.\n",
    "from value import Value\n",
    "from stdhk import StdHK # stdhk stands for \"Standard Heim & Kratzer\"\n",
    "Value.rules = StdHK\n",
    "\n",
    "\n",
    "# The meanings are lower-case named variables \n",
    "# They can be combined with \"+\"\n",
    "sentence1 = ahmed + smiles\n",
    "sentence2 = rosa + (loves + ahmed) # The parenthesis ensure that \"Ahmed\" is constituent at LF with \"loves\"\n",
    "sentence3 = (every + man) + smiles\n",
    "\n",
    "# The truth-values of the sentences against an empty assignment function can be obtained using the method val()\n",
    "print(\"Sentence 1 is\", sentence1.val())\n",
    "print(\"Sentence 2 is\", sentence2.val())\n",
    "print(\"Sentence 3 is\", sentence3.val())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The system can deal with assignment functions. Consider the following sentences/LFs:\n",
    "\n",
    " 1. Ahmed loves pro<sub>1</sub>\n",
    " 1. every man 1 Rosa loves t<sub>1</sub>\n",
    "\n",
    "For these sentences, more logical vocabulary needs to be imported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If g maps 1 to Rosa, sentence 4 is True\n",
      "Sentence 5 is False\n"
     ]
    }
   ],
   "source": [
    "# Importing binders and pronouns/traces\n",
    "from logical import pro, binder\n",
    "\n",
    "# These items take a numerical index as an argument\n",
    "sentence4 = ahmed + (loves + pro(1))\n",
    "sentence5 = (every + man) + (binder(1) + (rosa + (loves + pro(1))))\n",
    "\n",
    "# Sentence 4 cannot be evaluated against an empty assignment function\n",
    "# Assignemnent functions are implemented as dictionaries\n",
    "# They can be passed as arguments to val()\n",
    "print(\"If g maps 1 to Rosa, sentence 4 is\", sentence1.val({1 : \"Rosa\"}))\n",
    "\n",
    "# SUBTLE POINT : can be ignored\n",
    "# The assignment function should contain individuals (i.e. \"Rosa\"), not semantic values (i.e. rosa)\n",
    "# This is because semantic values encode their dependency to contexts\n",
    "# See later\n",
    "\n",
    "# Sentence 5 can be evaluated in an empty context\n",
    "print(\"Sentence 5 is\", sentence5.val())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Type mismatch raises an exception. For instance, the following LF for instance:\n",
    "\n",
    "  1. (Ahmed Ren) smiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeMismatch",
     "evalue": "Types e and e can't combine.\n Rules are: [<stdhk.FA object at 0x000001C8F2F53470>, <stdhk.Abstraction object at 0x000001C8F2F534E0>, <stdhk.PredicateModification object at 0x000001C8F2F53518>]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeMismatch\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-0c2b0834a5c7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msentence6\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mahmed\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mren\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msmiles\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Keny\\ProjetsPython\\Semantics\\value.py\u001b[0m in \u001b[0;36m__add__\u001b[1;34m(self, other, option)\u001b[0m\n\u001b[0;32m     28\u001b[0m                                         \u001b[1;32mreturn\u001b[0m \u001b[0mrule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcombine_val\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m                         \u001b[1;32mraise\u001b[0m \u001b[0mTypeMismatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mValue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrules\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m                         \u001b[1;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeMismatch\u001b[0m: Types e and e can't combine.\n Rules are: [<stdhk.FA object at 0x000001C8F2F53470>, <stdhk.Abstraction object at 0x000001C8F2F534E0>, <stdhk.PredicateModification object at 0x000001C8F2F53518>]"
     ]
    }
   ],
   "source": [
    "sentence6 = (ahmed + ren) + smiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced functionality\n",
    "\n",
    "### Creating one's own lexical items\n",
    "\n",
    "Lexical items have two components: a type and a value."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
